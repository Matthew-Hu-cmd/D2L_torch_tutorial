{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 锚框技术 anchor box  \n",
    "目标检测的一个任务是希望能够把物体处在的位置框选出来，我们会大范围的采样来判断这些区域是否包含我们感兴趣的目标，并调整区域边界，从而更加准确地预测*真实边界框*（ground-truth bounding box）  \n",
    "主流的目标检测算法是基于锚框来实现的：  \n",
    "* 以每个像素为中心，生成多个缩放比和宽高比（aspect ratio）不同的边界框\n",
    "* 预测每个锚框内部是否含有关注的物体  \n",
    "* 如果是，预测这个锚框到真实边缘框的偏移  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "torch.set_printoptions(2)  # 精简输出精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def multibox_prior(data, sizes, ratios):\n",
    "    \"\"\"生成以每个像素为中心具有不同形状的锚框\"\"\"\n",
    "    in_height, in_width = data.shape[-2:]\n",
    "    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n",
    "    boxes_per_pixel = (num_sizes + num_ratios - 1)\n",
    "    size_tensor = torch.tensor(sizes, device=device)\n",
    "    ratio_tensor = torch.tensor(ratios, device=device)\n",
    "\n",
    "    # 为了将锚点移动到像素的中心，需要设置偏移量。\n",
    "    # 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5\n",
    "    offset_h, offset_w = 0.5, 0.5\n",
    "    steps_h = 1.0 / in_height  # 在y轴上缩放步长\n",
    "    steps_w = 1.0 / in_width  # 在x轴上缩放步长\n",
    "\n",
    "    # 生成锚框的所有中心点\n",
    "    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n",
    "    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n",
    "    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n",
    "    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n",
    "\n",
    "    # 生成“boxes_per_pixel”个高和宽，\n",
    "    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax)\n",
    "    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n",
    "                   * in_height / in_width  # 处理矩形输入\n",
    "    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n",
    "    # 除以2来获得半高和半宽\n",
    "    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n",
    "                                        in_height * in_width, 1) / 2\n",
    "\n",
    "    # 每个中心点都将有“boxes_per_pixel”个锚框，\n",
    "    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n",
    "    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n",
    "                dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n",
    "    output = out_grid + anchor_manipulations\n",
    "    return output.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IoU-交并比  \n",
    "计算两个锚框之间的相似度，量化方式：  \n",
    "*杰卡德系数*（Jaccard）可以衡量两组之间的相似性。\n",
    "给定集合$\\mathcal{A}$和$\\mathcal{B}$，他们的杰卡德系数是他们交集的大小除以他们并集的大小：\n",
    "\n",
    "$$J(\\mathcal{A},\\mathcal{B}) = \\frac{\\left|\\mathcal{A} \\cap \\mathcal{B}\\right|}{\\left| \\mathcal{A} \\cup \\mathcal{B}\\right|}.$$\n",
    "\n",
    "事实上，我们可以将任何边界框的像素区域视为一组像素。通过这种方式，我们可以通过其像素集的杰卡德系数来测量两个边界框的相似性。\n",
    "对于两个边界框，它们的杰卡德系数通常称为*交并比*（intersection over union，IoU），即两个边界框相交面积与相并面积之比，\n",
    "![交并比是两个边界框相交面积与相并面积之比。](../img/iou.svg)\n",
    "使用交并比来衡量锚框和真实边界框之间、以及不同锚框之间的相似度。\n",
    "给定两个锚框或边界框的列表，以下`box_iou`函数将在这两个列表中计算它们成对的交并比。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成多个锚框\n",
    "\n",
    "假设输入图像的高度为$h$，宽度为$w$。\n",
    "我们以图像的每个像素为中心生成不同形状的锚框：*缩放比*为$s\\in (0, 1]$，*宽高比*为$r > 0$。\n",
    "那么[**锚框的宽度和高度分别是$ws\\sqrt{r}$和$hs/\\sqrt{r}$。**]\n",
    "请注意，当中心位置给定时，已知宽和高的锚框是确定的。\n",
    "\n",
    "要生成多个不同形状的锚框，让我们设置许多缩放比（scale）取值$s_1,\\ldots, s_n$和许多宽高比（aspect ratio）取值$r_1,\\ldots, r_m$。\n",
    "当使用这些比例和长宽比的所有组合以每个像素为中心时，输入图像将总共有$whnm$个锚框。\n",
    "尽管这些锚框可能会覆盖所有真实边界框，但计算复杂性很容易过高。\n",
    "在实践中，(**我们只考虑**)包含$s_1$或$r_1$的（否则太大了）\n",
    "\n",
    "$$(s_1, r_1), (s_1, r_2), \\ldots, (s_1, r_m),   ｜\n",
    "(s_2, r_1), (s_3, r_1), \\ldots, (s_n, r_1).$$\n",
    "\n",
    "\n",
    "也就是说，以同一像素为中心的锚框的数量是$n+m-1$。\n",
    "对于整个输入图像，将共生成$wh(n+m-1)$个锚框。\n",
    "\n",
    "上述生成锚框的方法在下面的`multibox_prior`函数中实现。\n",
    "我们指定输入图像、尺寸列表和宽高比列表，然后此函数将返回所有的锚框。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = d2l.plt.imread('../img/catdog.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "print(h, w)\n",
    "X = torch.rand(size=(1, 3, h, w))\n",
    "Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = Y.reshape(h, w, 5, 4)\n",
    "boxes[250, 250, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def show_bboxes(axes, bboxes, labels=None, colors=None):\n",
    "    \"\"\"显示所有边界框\"\"\"\n",
    "    def _make_list(obj, default_values=None):\n",
    "        if obj is None:\n",
    "            obj = default_values\n",
    "        elif not isinstance(obj, (list, tuple)):\n",
    "            obj = [obj]\n",
    "        return obj\n",
    "\n",
    "    labels = _make_list(labels)\n",
    "    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        color = colors[i % len(colors)]\n",
    "        rect = d2l.bbox_to_rect(bbox.detach().numpy(), color)\n",
    "        axes.add_patch(rect)\n",
    "        if labels and len(labels) > i:\n",
    "            text_color = 'k' if color == 'w' else 'w'\n",
    "            axes.text(rect.xy[0], rect.xy[1], labels[i],\n",
    "                      va='center', ha='center', fontsize=9, color=text_color,\n",
    "                      bbox=dict(facecolor=color, lw=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.set_figsize()\n",
    "bbox_scale = torch.tensor((w, h, w, h))\n",
    "fig = d2l.plt.imshow(img)\n",
    "show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale,\n",
    "            ['s=0.75, r=1', 's=0.5, r=1', 's=0.25, r=1', 's=0.75, r=2',\n",
    "             's=0.75, r=0.5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 赋予锚框标号  （训练的过程完成）\n",
    "* 每个锚框是一个训练样本  \n",
    "* 锚框要么是背景要么并联一个真实边缘框  \n",
    "* 我们可能会生成大量的锚框：  \n",
    "    * 导致大量负类样本  \n",
    "\n",
    "![算法步骤](../img/anchor-label.svg)  \n",
    "给定图像，假设锚框是$A_1, A_2, \\ldots, A_{n_a}$，真实边界框是$B_1, B_2, \\ldots, B_{n_b}$，其中$n_a \\geq n_b$。\n",
    "定义一个矩阵$\\mathbf{X} \\in \\mathbb{R}^{n_a \\times n_b}$，其中第$i$行、第$j$列的元素$x_{ij}$是锚框$A_i$和真实边界框$B_j$的IoU。\n",
    "该算法包含以下步骤。\n",
    "\n",
    "1. 在矩阵$\\mathbf{X}$中找到最大的元素，并将它的行索引和列索引分别表示为$i_1$和$j_1$。然后将真实边界框$B_{j_1}$分配给锚框$A_{i_1}$。$A_{i_1}$和$B_{j_1}$是所有锚框和真实边界框配对中最相近的(IoU值越大越接近)。在第一个分配完成后，丢弃矩阵中${i_1}^\\mathrm{th}$行和${j_1}^\\mathrm{th}$列中的所有元素。\n",
    "1. 在矩阵$\\mathbf{X}$中找到剩余元素中最大的元素，并将它的行索引和列索引分别表示为$i_2$和$j_2$。我们将真实边界框$B_{j_2}$分配给锚框$A_{i_2}$，并丢弃矩阵中${i_2}^\\mathrm{th}$行和${j_2}^\\mathrm{th}$列中的所有元素。\n",
    "1. 此时，矩阵$\\mathbf{X}$中两行和两列中的元素已被丢弃。我们继续，直到丢弃掉矩阵$\\mathbf{X}$中$n_b$列中的所有元素。此时已经为这$n_b$个锚框各自分配了一个真实边界框。\n",
    "1. 只遍历剩下的$n_a - n_b$个锚框。例如，给定任何锚框$A_i$，在矩阵$\\mathbf{X}$的第$i^\\mathrm{th}$行中找到与$A_i$的IoU最大的真实边界框$B_j$，只有当此IoU大于预定义的阈值时，才将$B_j$分配给$A_i$。  \n",
    "最终可能是会出现一张图片的锚框全都变成了背景，造成一张图片里面有大量被标注成背景的数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMS非极大抑制输出  （预测时实现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def multibox_prior(data, sizes, ratios):\n",
    "    \"\"\"生成以每个像素为中心具有不同形状的锚框\"\"\"\n",
    "    in_height, in_width = data.shape[-2:]\n",
    "    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n",
    "    boxes_per_pixel = (num_sizes + num_ratios - 1)\n",
    "    size_tensor = torch.tensor(sizes, device=device)\n",
    "    ratio_tensor = torch.tensor(ratios, device=device)\n",
    "\n",
    "    # 为了将锚点移动到像素的中心，需要设置偏移量。\n",
    "    # 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5\n",
    "    offset_h, offset_w = 0.5, 0.5\n",
    "    steps_h = 1.0 / in_height  # 在y轴上缩放步长\n",
    "    steps_w = 1.0 / in_width  # 在x轴上缩放步长\n",
    "\n",
    "    # 生成锚框的所有中心点\n",
    "    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n",
    "    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n",
    "    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n",
    "    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n",
    "\n",
    "    # 生成“boxes_per_pixel”个高和宽，\n",
    "    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax)\n",
    "    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n",
    "                   * in_height / in_width  # 处理矩形输入\n",
    "    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n",
    "    # 除以2来获得半高和半宽\n",
    "    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n",
    "                                        in_height * in_width, 1) / 2\n",
    "\n",
    "    # 每个中心点都将有“boxes_per_pixel”个锚框，\n",
    "    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n",
    "    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n",
    "                dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n",
    "    output = out_grid + anchor_manipulations\n",
    "    return output.unsqueeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
