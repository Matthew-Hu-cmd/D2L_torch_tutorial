{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全卷积神经网络  \n",
    "fully convolutional network，FCN  \n",
    "通过使用转置卷积，全卷积网络将中间层特征图的高和宽变换回输入图像的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型构造：\n",
    "* 基本的卷积神经网络提取特征  \n",
    "* 1x1卷积将通道数变换为类别个数  \n",
    "* 最终转置卷积将特征图的高和宽变化为输入图像尺寸，因此，模型输出与输入图像高宽相同，并且最终输出的通道包含该空间位置像素类别的预测。  \n",
    "![最简单的可以用于分割的模型](../img/fcn.svg) . \n",
    "使用在ImageNet数据集上预训练的ResNet-18模型来提取图像特征，并将该网络记为pretrained_net。 ResNet-18模型的最后几层包括全局平均汇聚层和全连接层，然而全卷积网络中不需要它们"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained_net = torchvision.models.resnet18(pretrained=True)\n",
    "list(pretrained_net.children())[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全卷积网络net:它复制了ResNet-18中大部分的预训练层，除了最后的全局平均汇聚层和最接近输出的全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(*list(pretrained_net.children())[:-2])\n",
    "# 给定高度为320和宽度为480的输入，net的前向传播将输入的高和宽减小至原来的1/32 \n",
    "X = torch.rand(size=(1, 3, 320, 480))\n",
    "net(X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
